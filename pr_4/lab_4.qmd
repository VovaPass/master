---
title: "Lab4"
author: vov41234567890@yandex.ru
date: "2025-11-22"
format: md
output-file: README.md
---

# Цель работы

1.Зекрепить практические навыки использования языка программирования R для обработки данных

2.Закрепить знания основных функций обработки данных экосистемы tidyverse языка R

3.Закрепить навыки исследования метаданных DNS трафика

# План

1. Импортируйте данные DNS – https://storage.yandexcloud.net/dataset.ctfsec/dns.zip Данные были собраны с помощью сетевого анализатора zeek

2. Добавьте пропущенные данные о структуре данных (назначении столбцов)

3. Преобразуйте данные в столбцах в нужный формат,просмотрите общую структуру данных с помощью функции glimpse()

4. Сколько участников информационного обмена всети Доброй Организации?

5. Какое соотношение участников обмена внутрисети и участников обращений к внешним ресурсам?

6. Найдите топ-10 участников сети, проявляющих наибольшую сетевую активность.

7. Найдите топ-10 доменов, к которым обращаются пользователи сети и соответственное количество обращений

8. Опеределите базовые статистические характеристики (функция summary() ) интервала времени между последовательными обращениями к топ-10 доменам.

9. Часто вредоносное программное обеспечение использует DNS канал в качестве канала управления, периодически отправляя запросы на подконтрольный злоумышленникам DNS сервер. По периодическим запросам на один и тот же домен можно выявить скрытый DNS канал. Есть ли такие IP адреса в исследуемом датасете?

10. Определите местоположение (страну, город) и организацию-провайдера для топ-10 доменов. Для этого можно использовать сторонние сервисы,например http://ip-api.com (API-эндпоинт – http://ip-api.com/json).

```{r}     
print(sessionInfo())
```

## Произведем установку и загрузку вспомогательных файлов

```{r}       
# Устанавливаем зеркало CRAN
options(repos = c(CRAN = "https://cloud.r-project.org"))

# Устанавливаем пакеты
install.packages("dplyr", repos = "https://cloud.r-project.org")
install.packages("readr")
install.packages("tidyr") 
install.packages("stringr")

library(readr)
library(tidyr)
library(stringr)
library(dplyr)
```

## Импорт данных

```{r}         
url <- "https://storage.yandexcloud.net/dataset.ctfsec/dns.zip"
 
 download.file(url, destfile = "dns.zip", mode = "wb") 
```

## Распаковка данных из архива

```{r}          
unzip("dns.zip", exdir = "dns_data")
 
```

## Проверка работоспособности импортированных данных

```{r}          
 readLines("dns_data/dns.log", n = 50)
```

## Преобразование данных в нужный формат

```{r}          
library(readr)

dns <- read_tsv("dns_data/dns.log", col_names = FALSE, col_types = cols(.default = "c"), quote = "")

colnames(dns) <- c("ts", "uid", "id_orig_h", "id_orig_p", "id_resp_h", "id_resp_p",
                   "proto", "trans_id", "query", "qclass", "qclass_name", "qtype",
                   "qtype_name", "rcode", "rcode_name", "AA", "TC", "RD", "RA",
                   "Z", "answers", "TTLs", "rejected")
```

## Просмотр с помощью функции glimpse()

```{r}          
glimpse(dns)
```

## Подсчет кол-ва участников информационного обмена в сети

```{r}          
length(unique(dns$id_orig_h[str_detect(dns$id_orig_h, "^192\\.168\\.202\\.")]))
```

## Соотношение участников обмена внутри

сети и участников обращений к внешним ресурсам?

```{r}          
summarise(dns, ratio = length(unique(c(id_orig_h[grepl("^192\\.168\\.", id_orig_h)], id_resp_h[grepl("^192\\.168\\.", id_resp_h)]))) / length(unique(id_orig_h[grepl("^192\\.168\\.", id_orig_h) & !grepl("^192\\.168\\.", id_resp_h)])))
```

## Топ-10 участников сети, проявляющих наибольшую сетевую активность.

```{r}          
dns %>% count(id_orig_h, sort = TRUE) %>% top_n(10, n)
```

## Топ-10 доменов, к которым обращаются пользователи сети и соответственное количество обращений

``` {r}         
 dns %>% count(query, sort = TRUE) %>% top_n(10, n)
```

## Опеределите базовые статистические характеристики (функция summary() ) интервала времени между последовательными обращениями к топ-10 доменам.

``` {r}         
top_domains <- dns %>%
  group_by(query) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  head(10) %>%
  pull(query)

# Теперь выполните ваш запрос
result <- dns %>%
  filter(query %in% top_domains) %>%
  arrange(query, as.numeric(ts)) %>%
  group_by(query) %>%
  mutate(interval = c(NA, diff(as.numeric(ts)))) %>%
  summarise(interval_stats = list(summary(interval, na.rm = TRUE)))

# Выведите результат
result
```

## Часто вредоносное программное обеспечение использует DNS канал в качестве канала управления, периодически отправляя запросы на подконтрольный злоумышленникам DNS сервер. По периодическим запросам на один и тот же домен можно выявить скрытый DNS канал. Есть ли такие IP адреса в исследуемом датасете?

``` {r}         
dns %>%
  arrange(id_orig_h, query, as.numeric(ts)) %>%
  group_by(id_orig_h, query) %>%
  mutate(int = diff(c(NA, as.numeric(ts)))) %>%
  summarise(sd_int = sd(int, na.rm = TRUE),
            mean_int = mean(int, na.rm = TRUE),
            n = n(),
            .groups="drop") %>%
  filter(n > 5, sd_int < mean_int * 0.1, mean_int > 0) %>%
  arrange(sd_int)
```

## Определите местоположение (страну, город) и организацию-провайдера для топ-10 доменов. Для этого можно использовать сторонние сервисы, например http:/ /ip-api.com (API-эндпоинт – http:/ /ip-api.com/json).

```{r}          
library(dplyr)
library(httr)
library(jsonlite)

## Топ-домены
top_domains <- c(
  "teredo.ipv6.microsoft.com",
  "tools.google.com",
  "www.apple.com",
  "time.apple.com",
  "safebrowsing.clients.google.com",
  "*\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00",
  "WPAD",
  "44.206.168.192.in-addr.arpa",
  "HPE8AA67",
  "ISATAP"
)

## Функция для получения геоданных по домену
get_geo_info <- function(domain) {
  url <- paste0("http://ip-api.com/json/", domain)
  res <- try(GET(url), silent = TRUE)
  
  if(inherits(res, "try-error")) return(data.frame(domain=domain, country=NA, city=NA, isp=NA))
  
  data <- fromJSON(content(res, as="text", encoding="UTF-8"))
  
  if(data$status == "success") {
    return(data.frame(
      domain = domain,
      country = data$country,
      city    = data$city,
      isp     = data$isp,
      stringsAsFactors = FALSE
    ))
  } else {
    return(data.frame(domain=domain, country=NA, city=NA, isp=NA, stringsAsFactors = FALSE))
  }
}

## Применяем к каждому домену
geo_df <- bind_rows(lapply(top_domains, get_geo_info))

## Результат
print(geo_df)
```

# Оценка результата

В рамках практческой работы была исследована подозрительная сетевая активность во внутренней сети Доброй Организации. Были восстановлены недостающие метаданные и подготовлены ответы на вопросы.

# Вывод

Таким мобразом в ходе работы мы зекрепили практические навыки использования языка программирования R для обработки данных, знания основных функций обработки данных экосистемы tidyverse языка R и навыки исследования метаданных DNS трафика
